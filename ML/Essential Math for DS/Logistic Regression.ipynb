{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP2SLh8Y9pgmp8Y19EUdcTL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## R Squared\n","R^2 indicates how well a given independent variable explains a dependent variable.\n","\n","Calculating the log likelihood of the fit"],"metadata":{"id":"XJuF0nKnl_g-"}},{"cell_type":"code","source":["from math import log, exp\n","import pandas as pd\n","\n","patient_data = pd.read_csv('https://bit.ly/33ebs2R', delimiter=\",\").itertuples()\n","\n","b0 = -3.17576395\n","b1 = 0.69267212\n","def logistic_function(x):\n","  p = 1.0 / (1.0 + exp(-(b0 + b1 * x)))\n","  return p\n","\n","log_likelihood_fit = 0.0\n","\n","for p in patient_data:\n","  if p.y == 1.0:\n","    log_likelihood_fit += log(logistic_function(p.x))\n","  elif p.y == 0.0:\n","    log_likelihood_fit += log(1.0 - logistic_function(p.x))\n","\n","print(log_likelihood_fit)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X0IHqrgzp4wj","executionInfo":{"status":"ok","timestamp":1706002275102,"user_tz":-330,"elapsed":3,"user":{"displayName":"Parth","userId":"02119677018501610637"}},"outputId":"7dc9c3de-e1d4-44a9-8ca3-a07354f53ad4"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["-9.946161673231583\n"]}]},{"cell_type":"markdown","source":["## Calculating R^2"],"metadata":{"id":"YIsLn9Dgryeu"}},{"cell_type":"code","source":["import pandas as pd\n","from math import log, exp\n","patient_data = list(pd.read_csv('https://bit.ly/33ebs2R', delimiter=\",\") \\\n","                                .itertuples())\n","b0 = -3.17576395\n","b1 = 0.69267212\n","\n","def logistic_function(x):\n","  p = 1.0 / (1.0 + exp(-(b0 + b1 * x)))\n","  return p\n","\n","# calculate the log likelihood of the fit\n","log_likelihood_fit = sum(log(logistic_function(p.x)) * p.y +\n","                         log(1.0 - logistic_function(p.x)) * (1.0 - p.y)\n","                         for p in patient_data)\n","\n","# calculate the log likelihood without fit\n","likelihood = sum(p.y for p in patient_data) / len(patient_data)\n","log_likelihood = sum(log(likelihood) * p.y + log(1.0 - likelihood) * (1.0 - p.y) \\\n","                     for p in patient_data) # calculate R-Square\n","\n","r2 = (log_likelihood - log_likelihood_fit) / log_likelihood\n","print(r2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yqsz_NLIr0n7","executionInfo":{"status":"ok","timestamp":1706002867963,"user_tz":-330,"elapsed":1101,"user":{"displayName":"Parth","userId":"02119677018501610637"}},"outputId":"56b062a1-f694-4f94-cd34-8d5898bf802b"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["0.306456105756576\n"]}]},{"cell_type":"markdown","source":["## P Values\n","Chi-square distribution, annotated as Ï‡2 distribution. It is continuous and used in several areas of statistics"],"metadata":{"id":"mE5wDAWysin_"}},{"cell_type":"code","source":["import pandas as pd\n","from math import log, exp\n","from scipy.stats import chi2\n","\n","patient_data = list(pd.read_csv('https://bit.ly/33ebs2R', delimiter=\",\").itertuples())\n","\n","# Declare fitted logistic regression\n","b0 = -3.17576395\n","b1 = 0.69267212\n","\n","def logistic_function(x):\n","  p = 1.0 / (1.0 + exp(-(b0 + b1 * x)))\n","  return p\n","\n","# calculate the log likelihood of the fit\n","log_likelihood_fit = sum(log(logistic_function(p.x)) * p.y +\n","                         log(1.0 - logistic_function(p.x)) * (1.0 - p.y)\n","                         for p in patient_data)\n","\n","# calculate the log likelihood without fit\n","likelihood = sum(p.y for p in patient_data) / len(patient_data)\n","log_likelihood = sum(log(likelihood) * p.y + log(1.0 - likelihood) * (1.0 - p.y) \\\n","                     for p in patient_data)\n","\n","# calculate p-value\n","chi2_input = 2 * (log_likelihood_fit - log_likelihood)\n","p_value = chi2.pdf(chi2_input, 1)\n","print(p_value)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gmmM_AMSuxvk","executionInfo":{"status":"ok","timestamp":1706003577399,"user_tz":-330,"elapsed":1131,"user":{"displayName":"Parth","userId":"02119677018501610637"}},"outputId":"3da462c7-a969-4eaf-8083-e3189ea529fc"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["0.0016604875618753787\n"]}]},{"cell_type":"markdown","source":["## Train/Test Splits\n","\n","3 Fold Cross Validation"],"metadata":{"id":"gvW-NUEMvQlh"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import KFold, cross_val_score\n","\n","# Load the data\n","df = pd.read_csv(\"https://tinyurl.com/y6r7qjrp\", delimiter=\",\")\n","X = df.values[:, :-1]\n","Y = df.values[:, -1]\n","\n","# \"random_state\" is the random seed, which we fix to 7\n","kfold = KFold(n_splits=3, random_state=7, shuffle=True)\n","model = LogisticRegression(penalty='none')\n","results = cross_val_score(model, X, Y, cv=kfold)\n","print(\"Accuracy Mean: %.3f (stdev=%.3f)\" % (results.mean(), results.std()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sC8E0aCAvxvZ","executionInfo":{"status":"ok","timestamp":1706003757854,"user_tz":-330,"elapsed":2016,"user":{"displayName":"Parth","userId":"02119677018501610637"}},"outputId":"a65031bf-fbd6-4cf6-ecad-1408237cd342"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy Mean: 0.611 (stdev=0.000)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n","  warnings.warn(\n"]}]}]}